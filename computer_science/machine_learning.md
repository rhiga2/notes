Machine Learning
================
# Linear Regression
## Regularization
* MAP Interpretation of L2 Regularization: prior of weights $w$ are independent, zero mean Gaussians with variance $\sigma^2$.

# Bayesian Machine Learning
* Instead of finding an estimate for $y$ given $x$, we can instead find a distribution of $y$ given $x$ by integrating over the parameter space.
* Penalizes complexity since complex models have lower priors.
* Integrating over parameter space is intractible in many cases especially with large deep learning models that have billions of parameters.
